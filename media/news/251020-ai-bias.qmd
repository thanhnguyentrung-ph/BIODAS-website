---
title: "Tái định nghĩa Thiên lệch Dữ liệu: Bài học từ AI trong Y tế"
subtitle: "Considering Biased Data as Informative Artifacts in AI-Assisted Health Care"
title-block-banner: "#313d5d"
title-block-banner-color: "#ffffff"
description: ""
categories:
  - AI
  - Bias
  - Health Care
author: "Health Care và cộng sự | Dịch và biên tập: BIODAS Team"
date: 10/20/2025 # mm/dd/yyyy
toc: true
image: https://www.datasciencecentral.com/wp-content/uploads/2025/06/Understanding-Bias-in-AI-Models.png
aliases: 
  - /media/news/
---

![](https://assets-global.website-files.com/5ab16d21eba35cdb2416f449/64597a9d5b04415faed315e8_Bias%20Types%20in%20AI%20Healthcare.jpg){fig-align="center" class="img-cover"}



```{=html}
<!-- Gắn file CSS -->
<link rel="stylesheet" href="section-news-template.css">

<!-- Font Awesome CDN (hiển thị icon mạng xã hội) -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">


<body class="section-news-template">
<div class="layout">

  <!-- Sidebar TOC -->
  <nav class="toc">
    <h3>Mục lục</h3>
    <ol>
      <li><a href="#sec-1">Giới thiệu</a></li>
      <li><a href="#sec-2">Đặt vấn đề</a></li>
      <li><a href="#sec-3">Ba khía cạnh chính: Khi dữ liệu trở thành “tạo tác”</a></li>
      <li><a href="#sec-4">Hướng tiếp cận xã hội – kỹ thuật</a></li>
      <li><a href="#sec-5">Ứng dụng tại Việt Nam</a></li>
      <li><a href="#sec-6">Kết luận</a></li>
      <li><a href="#sec-7">Tài liệu tham khảo</a></li>
    </ol>
  </nav>

  <!-- Nội dung chính -->
  <main class="content">

    <!-- 1. Giới thiệu -->
    <section id="sec-1">
      <h2>1. Giới thiệu</h2>
      <p>
        Bài tổng quan 
        <strong>
          <a href="https://doi.org/10.1056/nejmra2214964" target="_blank" rel="noopener noreferrer" style="color:#313d5d; text-decoration:underline;">
            “Considering Biased Data as Informative Artifacts in AI-Assisted Health Care”
          </a>
        </strong> 
        của <em>Kadija Ferryman</em> (Johns Hopkins University), <em>Maxine Mackintosh</em> (Genomics England) 
        và <em>Marzyeh Ghassemi</em> (MIT), được đăng trên <em>The New England Journal of Medicine</em> (2023), 
        đã đặt ra một góc nhìn mới mẻ về dữ liệu y tế trong kỷ nguyên trí tuệ nhân tạo (AI).
      </p>

      <p>
        Thay vì xem dữ liệu bị thiên lệch như “rác thải kỹ thuật” cần loại bỏ theo quan niệm 
        <strong>“garbage in – garbage out”</strong>, nhóm tác giả cho rằng chính những sai lệch này 
        là <strong>“những tạo tác giàu thông tin” (informative artifacts)</strong> — phản chiếu 
        giá trị, tập quán và bất bình đẳng đã ăn sâu trong hệ thống y tế hiện đại. 
        Việc xem dữ liệu như những “di chỉ xã hội” có thể giúp chúng ta hiểu rõ hơn 
        về cách công nghệ phản ánh và đôi khi khuếch đại bất công trong chăm sóc sức khỏe.
      </p>

      <p>
        Quan điểm này gợi ý rằng, thay vì chỉ cố gắng “sửa lỗi” trong dữ liệu, 
        giới khoa học cần học cách “đọc hiểu” chúng — như cách các nhà khảo cổ học diễn giải những cổ vật 
        để hiểu về xã hội thời xưa. Dữ liệu lâm sàng, nếu được nhìn nhận như một loại “tạo tác”, 
        có thể tiết lộ nhiều điều về tổ chức bệnh viện, văn hóa nghề nghiệp, và cách xã hội đánh giá 
        sức khỏe và giá trị con người.
      </p>

      <div class="callout">
        <p>
          <strong>BIODAS Team</strong> giới thiệu tổng quan này nhằm khuyến khích tư duy phản biện về 
          cách dữ liệu và thuật toán định hình công bằng y tế. Khi hiểu rõ nguồn gốc của thiên lệch, 
          chúng ta có thể chuyển hóa AI từ công cụ dự đoán sang công cụ phát hiện bất bình đẳng sức khỏe.
        </p>
      </div>

    </section>

    <figure>
      <div class="img-wrap">
        <img src="https://www.nejm.org/cms/asset/163c849b-e0dd-4350-8bd8-449b82b00ab1/nejmra2214964_f1.jpg" class="img" />
      </div>
      <figcaption>
        Hình ảnh minh họa (Nguồn: https://www.nejm.org)
      </figcaption>
    </figure>


    <!-- 2. Đặt vấn đề -->
    <section id="sec-2">
      <h2>2. Đặt vấn đề</h2>
      <p>
        Trong chăm sóc sức khỏe hiện đại, các hệ thống AI phụ thuộc gần như hoàn toàn vào 
        những tập dữ liệu khổng lồ đã được gán nhãn. Khi những dữ liệu này phản ánh sự khác biệt 
        về chủng tộc, giới tính, hoặc điều kiện kinh tế – xã hội, AI có thể vô tình 
        <strong>tái tạo các định kiến xã hội</strong> — hiện tượng được gọi là 
        <em>phân biệt đối xử thuật toán (algorithmic discrimination)</em>.
      </p>

      <div class="card">
        <p>
          Ví dụ, trong một nghiên cứu về X-quang ngực, hệ thống AI được huấn luyện bằng hàng nghìn hình ảnh 
          vẫn thể hiện xu hướng <strong>chẩn đoán thiếu (underdiagnosis)</strong> ở nhóm bệnh nhân da đen và 
          người gốc Mỹ Latin, đặc biệt là phụ nữ. Điều này xảy ra bởi vì 
          dữ liệu ban đầu vốn đã không phản ánh công bằng tình hình bệnh lý của các nhóm dân số.
        </p>
      </div>

      <p>
        Theo Ferryman và cộng sự, vấn đề không chỉ nằm ở dữ liệu “bị sai” mà còn ở cách chúng ta hiểu dữ liệu. 
        Dữ liệu lâm sàng là sản phẩm của bối cảnh xã hội, quy trình tổ chức và quyết định chuyên môn; 
        vì vậy, mỗi “thiên lệch” là một chỉ dấu của văn hóa và lịch sử ngành y. 
        Thay vì loại bỏ, chúng ta có thể học từ những thiên lệch đó để cải thiện công bằng sức khỏe.
      </p>
    </section>

    <figure>
      <div class="img-wrap">
        <img src="https://www.quantib.com/hs-fs/hubfs/assets/images/blog/Blog%20and%20news%20images/Example%20of%20algorithm%20bias%20in%20healthcare%20-%20coverage%20bias%20-%20AI%20in%20radiology%20-%20Quantib.png?width=1052&name=Example%20of%20algorithm%20bias%20in%20healthcare%20-%20coverage%20bias%20-%20AI%20in%20radiology%20-%20Quantib.png" class="img" />
      </div>
      <figcaption>
        Hình ảnh minh họa (Nguồn: https://www.quantib.com)
      </figcaption>
    </figure>

    <!-- 3. Ba khía cạnh -->
    <section id="sec-3">
      <h2>3. Ba khía cạnh chính: Khi dữ liệu trở thành “tạo tác”</h2>

      <h3>3.1. Dữ liệu và giá trị xã hội</h3>
      <div class="card">
        <p>
          “Hiệu chỉnh chủng tộc” trong ước tính chức năng thận (eGFR) từng được xem là cải tiến khoa học, 
          nhưng thực chất phản ánh giả định rằng người da đen có khối cơ cao hơn – một di sản từ thời 
          cơ thể nam giới da trắng được xem là “chuẩn mực sinh học”. 
          Khi những công thức này được đưa vào AI, chúng tiếp tục tái sản xuất định kiến chủng tộc 
          dưới lớp vỏ trung lập của thuật toán.
        </p>
        <p>
          Nhìn từ góc độ “tạo tác”, việc tồn tại các biến số “race correction” không chỉ là lỗi thống kê, 
          mà là dấu vết của một giai đoạn lịch sử khi khoa học y học được xây dựng trên nền tảng phân biệt chủng tộc. 
          Thừa nhận và phân tích nguồn gốc của các “giá trị ẩn” này chính là bước đầu tiên 
          để hướng tới AI y tế có trách nhiệm hơn.
        </p>
      </div>

      <h3>3.2. Dữ liệu và thực hành lâm sàng</h3>
      <div class="card">
        <p>
          Nhiều bệnh án điện tử thiếu dữ liệu về bản dạng giới, tình trạng khuyết tật hoặc yếu tố xã hội. 
          Sự “thiếu vắng dữ liệu” này không đơn thuần là lỗi kỹ thuật, 
          mà phản ánh sự thiếu đồng nhất trong ngôn ngữ y học, rào cản niềm tin giữa bác sĩ và bệnh nhân, 
          cũng như hạn chế trong đào tạo nhân viên y tế về đa dạng giới. 
          Theo nhóm tác giả, nếu tiếp cận theo hướng “tạo tác”, chúng ta có thể dùng AI 
          để nhận diện nơi nào dữ liệu bị thiếu, từ đó khơi mở các câu hỏi về công bằng và đại diện trong y tế.
        </p>
        <p>
          AI, khi được sử dụng đúng cách, có thể phát hiện những “khoảng trống dữ liệu” — 
          chẳng hạn như việc thiếu dữ liệu của nhóm dân tộc thiểu số hoặc bệnh nhân LGBTQ+ — 
          và biến chúng thành tín hiệu để nghiên cứu sâu hơn về bất bình đẳng hệ thống.
        </p>
      </div>

      <h3>3.3. Dữ liệu và bất bình đẳng sức khỏe</h3>
      <div class="card">
        <p>
          Trong lĩnh vực ung thư phổi, dữ liệu cho thấy bệnh nhân da đen thường được chẩn đoán muộn hơn người da trắng, 
          khiến AI “học” rằng nhóm này có tiên lượng xấu hơn. 
          Nếu không xem xét bối cảnh xã hội, mô hình AI sẽ củng cố chính những bất công mà nó nên khắc phục. 
          Khi coi dữ liệu như tạo tác, nhà nghiên cứu có thể phát hiện và làm sáng tỏ 
          những chuỗi loại trừ mang tính hệ thống trong y tế, chẳng hạn như sự thiếu tiếp cận 
          dịch vụ sàng lọc sớm, chi phí điều trị cao, hoặc định kiến trong quy trình phân loại bệnh.
        </p>
      </div>

      <div class="callout">
        <p><em>“Dữ liệu y tế không chỉ nói về bệnh nhân – chúng nói về toàn bộ hệ thống chăm sóc và những gì xã hội coi trọng.”</em></p>
      </div>
    </section>

    <!-- 4. Cách tiếp cận xã hội - kỹ thuật -->
    <section id="sec-4">
      <h2>4. Hướng tiếp cận xã hội – kỹ thuật (sociotechnical)</h2>
      <p>
        Ferryman và cộng sự đề xuất một khung phân tích kết hợp giữa công nghệ, đạo đức và xã hội, 
        nhằm mở rộng cách hiểu về thiên lệch dữ liệu. Thay vì chỉ “vá lỗi” kỹ thuật, 
        họ đề nghị một cách tiếp cận toàn diện hơn, kết hợp dữ liệu, con người và bối cảnh xã hội.
      </p>

      <div class="callout">
        <ul>
          <li><strong>Vượt qua “làm sạch dữ liệu”:</strong> Không chỉ loại bỏ sai lệch mà cần diễn giải nguyên nhân xã hội – lịch sử đằng sau dữ liệu đó.</li>
          <li><strong>Hợp tác liên ngành:</strong> Kết nối bác sĩ, kỹ sư, nhà đạo đức học, và nhà xã hội học để đồng kiến tạo giải pháp.</li>
          <li><strong>Đồng bộ với công bằng sức khỏe:</strong> Xem AI không chỉ là công cụ phát hiện bệnh, mà là công cụ phát hiện bất bình đẳng.</li>
        </ul>
      </div>

      <p>
        Cách tiếp cận này đưa AI ra khỏi phạm vi “công nghệ thuần túy”, 
        hướng tới một mô hình phát triển mang tính phản tư và nhân văn hơn. 
        Nó cũng mở ra cơ hội sử dụng AI như công cụ xã hội học để soi chiếu chính các cấu trúc bất công 
        mà dữ liệu phản ánh.
      </p>
    </section>

    <figure>
      <div class="img-wrap">
        <img src="https://www.wsp.com/-/media/insights/canada/image/2019/sociotechnical_system-en.png?h=399&iar=0&w=563&hash=FC79760F519720C6F8C9013AB24A4E5D" class="img" />
      </div>
      <figcaption>
        Hình ảnh minh họa (Nguồn: https://www.wsp.com)
      </figcaption>
    </figure>

    <!-- 5. Việt Nam -->
    <section id="sec-5">
      <h2>5. Ứng dụng tại Việt Nam</h2>
      <p>
        Trong bối cảnh Việt Nam đang xây dựng hạ tầng dữ liệu y tế quốc gia và triển khai bệnh án điện tử, 
        tư duy “dữ liệu như tạo tác” đặc biệt có ý nghĩa:
      </p>

      <div class="callout">
        <ul>
          <li>Giúp đánh giá thiên lệch tiềm ẩn trong dữ liệu y tế, từ vùng miền đến giới tính và điều kiện kinh tế.</li>
          <li>Đặt nền tảng cho khung đạo đức dữ liệu và chính sách minh bạch khi ứng dụng AI trong y tế công.</li>
          <li>Khuyến khích hợp tác giữa y học, khoa học dữ liệu và khoa học xã hội để đảm bảo công bằng sức khỏe.</li>
        </ul>
      </div>
      
      <p>
        Các dự án quốc gia như hồ sơ sức khỏe điện tử, dữ liệu tiêm chủng, hoặc hệ thống dự báo dịch bệnh 
        cần được thiết kế với ý thức xã hội – kỹ thuật này. 
        Việc lưu ý đến thiên lệch dữ liệu (ví dụ: bệnh nhân vùng sâu, dân tộc thiểu số ít được ghi nhận) 
        có thể giúp ngăn ngừa việc tái tạo bất bình đẳng trong y tế số.
      </p>
      <div class="callout">
        <p><em>Nhận diện thiên lệch không phải để loại bỏ dữ liệu, mà để hiểu sâu hơn về chính hệ thống đã sinh ra dữ liệu đó — từ đó kiến tạo công bằng y tế bền vững.</em></p>
      </div>
    </section>

    <!-- 6. Kết luận -->
    <section id="sec-6">
      <h2>6. Kết luận</h2>
      <p>
        “Thiên lệch dữ liệu” không chỉ là lỗi kỹ thuật – nó là tấm gương phản chiếu lịch sử, văn hóa và cấu trúc xã hội. 
        Khi xem dữ liệu như “tạo tác thông tin”, chúng ta có thể dùng AI để soi chiếu những bất bình đẳng tiềm ẩn, 
        thay vì vô tình củng cố chúng. 
      </p>
      <p>
        Đây chính là bước chuyển từ “AI chính xác” sang “AI công bằng” — 
        một hướng đi cần thiết để đảm bảo rằng tiến bộ công nghệ luôn gắn liền với nhân văn và công lý trong y học số. 
        Như Ferryman và đồng nghiệp kết luận, “một hệ thống AI y tế chỉ thực sự thông minh khi nó hiểu rõ lịch sử và giá trị con người ẩn trong dữ liệu mà nó học từ đó.”
      </p>
    </section>

    <!-- 7. Tài liệu tham khảo -->
    <section id="sec-7">
      <h2>7. Tài liệu tham khảo</h2>
      <ol>
        <li>Ferryman K, Mackintosh M, Ghassemi M. <em>Considering Biased Data as Informative Artifacts in AI-Assisted Health Care.</em> N Engl J Med. 2023;389(9):833–838. DOI: <a href="https://doi.org/10.1056/NEJMra2214964" target="_blank">10.1056/NEJMra2214964</a>.</li>
        <li>Obermeyer Z, Powers B, Vogeli C, Mullainathan S. <em>Dissecting racial bias in an algorithm used to manage the health of populations.</em> Science. 2019;366:447–453.</li>
        <li>Inker LA et al. <em>New creatinine- and cystatin C–based equations to estimate GFR without race.</em> N Engl J Med. 2021;385:1737–1749.</li>
        <li>Chen IY, Joshi S, Ghassemi M. <em>Treating health disparities with artificial intelligence.</em> Nat Med. 2020;26:16–17.</li>
      </ol>
    </section>

    <!-- SOCIAL SHARE -->
    <div class="social-section">
      <p class="share-note">Chia sẻ bài viết này</p>
      <div class="social-share">
        <a href="https://www.facebook.com/sharer/sharer.php?u=https://www.biodas.net/media/news/251020-ai-bias.html/" class="fb" title="Chia sẻ trên Facebook"><i class="fab fa-facebook-f"></i></a>
        <a href="https://twitter.com/intent/tweet?status=https://www.biodas.net/media/news/251020-ai-bias.html/" class="x" title="Chia sẻ trên X / Twitter"><i class="fab fa-x-twitter"></i></a>
        <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://biodas.net/media/news/251020-ai-bias.html/" class="in" title="Chia sẻ trên LinkedIn"><i class="fab fa-linkedin-in"></i></a>
      </div>
    </div>

  </main>
</div>

<!-- =============================
     SECTION: BIODAS NEWS & INSIGHTS
     ============================= -->
<section class="biodas-news-section">
  <div class="news-list container">
    <h2 class="section-title">MỘT SỐ TIN TỨC KHÁC</h2>
    <div id="biodas-news-grid" class="news-grid"></div>
  </div>
</section>


</body>




<!-- JS SCRIPT -->
<script src="section-news-template.js"></script>

```
